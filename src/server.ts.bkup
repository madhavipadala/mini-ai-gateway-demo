import "dotenv/config";
import express from "express";
import cors from "cors";
import morgan from "morgan";
import pino from "pino";
import fs from "fs";
import path from "path";
import Ajv from "ajv";
import addFormats from "ajv-formats";
import { RateLimiterMemory } from "rate-limiter-flexible";
import { fileURLToPath } from "url";

// ===== Robust startup logs =====
const log = pino({ level: "info" });
process.on("uncaughtException", (e) => { console.error("uncaughtException:", e); process.exit(1); });
process.on("unhandledRejection", (e) => { console.error("unhandledRejection:", e); process.exit(1); });
console.log("Booting Mini EHR AI Gateway…");

const app = express();
app.use(express.json({ limit: "256kb" }));
app.use(cors({ origin: true }));
app.use(morgan("tiny"));

// Friendly root
app.get("/", (_req, res) => res.type("text/plain").send("Mini EHR AI Gateway is running. Try GET /health"));

// Rate limiter
const limiter = new RateLimiterMemory({ points: Number(process.env.RATE_LIMIT_RPM ?? 30), duration: 60 });
app.use(async (req, res, next) => {
  try { await limiter.consume(req.ip); next(); }
  catch { return res.status(429).json({ error: "rate_limited" }); }
});

// Load schema with clear error
let schema: any;
try {
  const here = path.dirname(fileURLToPath(import.meta.url));
  const schemaPath = path.join(here, "schema", "ai_output_schema.json");
  console.log("Loading schema from:", schemaPath);
  schema = JSON.parse(fs.readFileSync(schemaPath, "utf-8"));
  console.log("Schema loaded OK");
} catch (e) {
  console.error("Failed to load schema:", e);
  process.exit(1);
}

const ajv = new Ajv({ allErrors: true, strict: false });
addFormats(ajv);
const validate = ajv.compile(schema);

// Helper to build the prompt
function buildPrompt(input: any) {
  const schemaInline = JSON.stringify(schema);
  const instructions = [
    "Return only valid JSON; do not include backticks.",
    "If unsure about a field, use null or an empty array.",
    "Keep differential to 2–6 items; one-sentence rationales."
  ].join(" ");
  return `SCHEMA:\n${schemaInline}\n\nINPUT:\n${JSON.stringify(input)}\n\nINSTRUCTIONS:\n${instructions}`;
}

// ===== Adapters =====
import { callOpenAI } from "./adapters/openai.js";
import { callInfermedica } from "./adapters/infermedica.js";
import { callIsabel } from "./adapters/isabel.js";

// Single-item diagnose helper
// Single-item diagnose helper
async function diagnoseOne(input: any, deidentified: boolean) {
  const allowPHI = String(process.env.ALLOW_PHI ?? "false") === "true";
  if (!allowPHI && !deidentified) {
    return { ok: false as const, error: "phi_not_allowed" };
  }

  const provider = String(process.env.PROVIDER || "openai");
  try {
    let result: any = null;

    if (provider === "openai") {
      const model = process.env.OPENAI_MODEL || "gpt-4o-mini";
      const apiKey = process.env.OPENAI_API_KEY || "";
      if (!apiKey) return { ok: false as const, error: "missing_api_key" };

      const temperature = Number(process.env.TEMPERATURE ?? 0.2);
      const maxTokens = Number(process.env.MAX_TOKENS ?? 800);

      const prompt = buildPrompt(input);
      const tryParse = (t: string): any | null => { try { return JSON.parse(t); } catch { return null; } };

      // Attempt 1
      let text = await callOpenAI(prompt, model, apiKey, temperature, maxTokens);
      result = tryParse(text);

      // Repair pass if invalid
      if (!result || !validate(result)) {
        const repairPrompt = prompt + "\n\nYour previous output was invalid. Re-emit JSON that strictly passes the schema. Do not add commentary.";
        text = await callOpenAI(repairPrompt, model, apiKey, temperature, maxTokens);
        result = tryParse(text);
      }

      if (!result || !validate(result)) {
        return { ok: false as const, error: "schema_validation_failed", details: validate.errors };
      }

      // Normalize engine + provenance
      const out: any = result;
      out.engine = out.engine || {};
      out.engine.name = out.engine.name || "openai";
      out.engine.version = out.engine.version || model;
      result = out;

    } else if (provider === "infermedica") {
      result = await callInfermedica(input, "API_KEY", "APP_ID"); // stub
    } else if (provider === "isabel") {
      result = await callIsabel(input, "API_KEY"); // stub
    } else {
      return { ok: false as const, error: "unknown_provider" };
    }

    // Provenance, final validation
    const finalOut: any = result;
    finalOut.provenance = finalOut.provenance || {};
    finalOut.provenance.generated_at = new Date().toISOString();

    if (!validate(finalOut)) {
      return { ok: false as const, error: "schema_validation_failed", details: validate.errors };
    }

    return { ok: true as const, output: finalOut };

  } catch (e: any) {
    return { ok: false as const, error: "server_error", details: String(e?.message || e) };
  }
}

// Tiny concurrency pool for batch
async function runPool<T>(concurrency: number, tasks: Array<() => Promise<T>>): Promise<T[]> {
  const results: T[] = [];
  let i = 0;
  const workers = new Array(Math.min(concurrency, tasks.length)).fill(0).map(async () => {
    while (i < tasks.length) {
      const idx = i++;
      results[idx] = await tasks[idx]();
    }
  });
  await Promise.all(workers);
  return results;
}

// ===== Routes =====
app.get("/health", (_req, res) => res.json({ ok: true }));

app.post("/ai/diagnose", async (req, res) => {
  const deid = !!req.body?.deidentified;
  const input = req.body?.input || {};
  const r = await diagnoseOne(input, deid);
  if (!r.ok) return res.status(400).json({ error: r.error, details: (r as any).details });
  return res.json((r as any).output);
});

app.post("/ai/diagnose/batch", async (req, res) => {
  try {
    const max = Number(process.env.BATCH_MAX ?? 20);
    const concurrency = Number(process.env.BATCH_CONCURRENCY ?? 3);

    const topDeid = !!req.body?.deidentified;
    const items = Array.isArray(req.body?.items) ? req.body.items : [];

    if (!items.length) return res.status(400).json({ error: "invalid_request", message: "items[] required" });
    if (items.length > max) return res.status(400).json({ error: "too_many_items", max });

    const tasks = items.map((it: any) => {
      const deid = (typeof it?.deidentified === "boolean") ? !!it.deidentified : topDeid;
      const input = it?.input || {};
      const meta  = it?.meta || null;

      return async () => {
        const r = await diagnoseOne(input, deid);
        return { ok: (r as any).ok, output: (r as any).output, error: (r as any).error, details: (r as any).details, meta };
      };
    });

    const raw = await runPool(concurrency, tasks);

    let ok = 0, failed = 0;
    const results = raw.map((r, index) => {
      if ((r as any).ok) ok++; else failed++;
      return { index, ...(r as any) };
    });

    return res.json({ summary: { total: items.length, ok, failed }, results });

  } catch (e: any) {
    return res.status(500).json({ error: "server_error", message: String(e?.message || e) });
  }
});

const port = Number(process.env.PORT || 8888);
app.listen(port, () => {
  console.log("AI Gateway listening on", port);
  log.info({ port }, "AI Gateway listening");
});
